# ength box plot
ggplot(data = dat) +
geom_boxplot(aes(y = length, yend = length), size = 0.3, color = "red") +
theme_classic()+
theme(axis.title.y = element_text(color = "orange")) +
ylab("Length")
# Above 0.8 = sufficient power
# Below 0.8 = not sufficient power
wp.correlation(n = 50, r = 0.3, alpha = 0.05)
library(WebPower)
# Above 0.8 = sufficient power
# Below 0.8 = not sufficient power
wp.correlation(n = 50, r = 0.3, alpha = 0.05)
# TO get it above 0.8, we can change r and/or sample size. Do not recommend changing alpha
wp.correlation(n = 50, r = 0.384, alpha = 0.05)
# TO get it above 0.8, we can change r and/or sample size. Do not recommend changing alpha
wp.correlation(n = 50, r = 0.384, alpha = 0.1)
# TO get it above 0.8, we can change r and/or sample size. Do not recommend changing alpha
wp.correlation(n = 50, r = 0.384, alpha = 0.1)
# TO get it above 0.8, we can change r and/or sample size. Do not recommend changing alpha
wp.correlation(n = 50, r = 0.384, alpha = 0.001)
# TO get it above 0.8, we can change r and/or sample size. Do not recommend changing alpha
wp.correlation(n = 50, r = 0.384, alpha = 0.05)
# TO get it above 0.8, we can change r and/or sample size. Do not recommend changing alpha
wp.correlation(n = 50, r = 0.384, alpha = 0.5)
0
# TO get it above 0.8, we can change r and/or sample size. Do not recommend changing alpha
wp.correlation(n = 50, r = 0.384, alpha = 0.05)
# Fixed contraints, can only afford 50 samples
wp.correlation(n = 50, alpha = 0.05, power = 0.8)
wp.correlation(r = 0.3, alpha = 0.05, power = 0.8)
# plot sample size power
example <- wp.correlation(n=seq(50, 100, 10),
0.3, alpha = 0.05)
plot(example)
# D = effect size, how many stds away
wp.t(n1 = NULL, d = 0.03, power = 0.08, type = "paired")
wp.t(n1 = NULL, d = 0.03, power = 0.08, type = "two.sample")
# We can sample 1000
# Dont know effect size
# What effect size can we detect
wp.t(n1 = 1000, d = NULL, power = 0.8, type = "two.sample")
# .2n is for when we have two sample sizes
wp.t(n1 = 100, n2 = 250, d = 0.5, power = NULL, type = "two.sample.2n")
setwd("C:/Users/ahmad/Desktop/OneDrive - Rensselaer Polytechnic Institute/RPI(F25)/DataAnalytics2025_Ayaan_Ahmad/Lab3")
library(tidyverse)
abalone_data <- read.csv("abalone_dataset.csv")
# EXERCISE 1
abalone_data$age_group <- cut(abalone_data$rings, br =c (0, 8, 11, 35),
labels = c("young", "adult", "old"))
## alternative way of setting age.group
abalone_data$age_group[abalone_data$rings <= 8] <- "young"
abalone_data$age_group[abalone_data$rings > 8 & abalone_data$rings<=11] <- "adult"
abalone_data$age_group[abalone_data$rings > 11 & abalone_data$rings<=35] <- "old"
library(tidyverse)
library(class)
View(abalone_data)
View(abalone_data)
library(tidyverse)
abalone_data <- read.csv("abalone_dataset.csv")
# EXERCISE 1
## alternative way of setting age.group
abalone_data$age_group[abalone_data$rings <= 8] <- "young"
abalone_data$age_group[abalone_data$rings > 8 & abalone_data$rings<=11] <- "adult"
abalone_data$age_group[abalone_data$rings > 11 & abalone_data$rings<=35] <- "old"
library(tidyverse)
library(class)
# Found a typo
names(abalone_data)[names(abalone_data) == "shucked_wieght"] <- "shucked_weight"
library(tidyverse)
abalone_data <- read.csv("abalone_dataset.csv")
# EXERCISE 1
abalone_data$age_group <- cut(abalone_data$rings, br =c (0, 8, 11, 35),
labels = c("young", "adult", "old"))
## alternative way of setting age.group
abalone_data$age_group[abalone_data$rings <= 8] <- "young"
abalone_data$age_group[abalone_data$rings > 8 & abalone_data$rings<=11] <- "adult"
abalone_data$age_group[abalone_data$rings > 11 & abalone_data$rings<=35] <- "old"
library(tidyverse)
library(class)
# Found a typo
names(abalone_data)[names(abalone_data) == "shucked_wieght"] <- "shucked_weight"
# Define the target variable
target <- abalone_data$rings
# Split data into training (70%) and testing (30%) sets
train_indices <- sample(1:nrow(abalone_data), 0.7 * nrow(abalone_data))
train_data <- abalone_data[train_indices, ]
test_data <- abalone_data[-train_indices, ]
# Model 1: Use all numerical features (excluding rings)
features1 <- c("sex", "length", "diameter", "height", "whole_weight", "shucked_weight", "viscera_weight", "shell_weight")
train_features1 <- train_data[, features1]
# Model 1: Use all numerical features (excluding rings)
features1 <- c("length", "diameter", "height", "whole_weight", "shucked_weight", "viscera_weight", "shell_weight")
train_features1 <- train_data[, features1]
test_features1 <- test_data[, features1]
library(tidyverse)
abalone_data <- read.csv("abalone_dataset.csv")
# EXERCISE 1
abalone_data$age_group <- cut(abalone_data$rings, br =c (0, 8, 11, 35),
labels = c("young", "adult", "old"))
## alternative way of setting age.group
abalone_data$age_group[abalone_data$rings <= 8] <- "young"
abalone_data$age_group[abalone_data$rings > 8 & abalone_data$rings<=11] <- "adult"
abalone_data$age_group[abalone_data$rings > 11 & abalone_data$rings<=35] <- "old"
library(tidyverse)
library(class)
# Found a typo
names(abalone_data)[names(abalone_data) == "shucked_wieght"] <- "shucked_weight"
# Convert 'sex' to numeric for kNN (M=1, F=2, I=3)
abalone_data$sex <- as.numeric(factor(abalone_data$sex, levels = c("M", "F", "I")))
# Define the target variable
target <- abalone_data$rings
# Split data into training (70%) and testing (30%) sets
train_indices <- sample(1:nrow(abalone_data), 0.7 * nrow(abalone_data))
train_data <- abalone_data[train_indices, ]
test_data <- abalone_data[-train_indices, ]
# Model 1: Use all numerical features (excluding rings)
features1 <- c("sex", "length", "diameter", "height", "whole_weight", "shucked_weight", "viscera_weight", "shell_weight")
train_features1 <- train_data[, features1]
library(tidyverse)
library(class)
abalone_data <- read.csv("abalone_dataset.csv")
# EXERCISE 1
abalone_data$age_group <- cut(abalone_data$rings, br =c (0, 8, 11, 35),
labels = c("young", "adult", "old"))
## alternative way of setting age.group
abalone_data$age_group[abalone_data$rings <= 8] <- "young"
abalone_data$age_group[abalone_data$rings > 8 & abalone_data$rings<=11] <- "adult"
abalone_data$age_group[abalone_data$rings > 11 & abalone_data$rings<=35] <- "old"
abalone_data$sex <- as.numeric(as.factor(abalone_data$sex))
# Split data into a 70% training set and a 30% testing set.
train_indices <- sample(1:nrow(abalone_data), 0.7 * nrow(abalone_data))
train_data <- abalone_data[train_indices, ]
test_data <- abalone_data[-train_indices, ]
# Separate the target variable (labels) from the feature sets.
train_labels <- train_data$age_group
test_labels <- test_data$age_group
# --- Model 1: Using a broad set of physical measurement features ---
features1 <- c("sex", "length", "diameter", "height", "whole_weight",
"shucked_weight", "viscera_weight", "shell_weight")
# Normalize the features for both training and testing sets.
# kNN is sensitive to the scale of data, so normalization is crucial.
train_features1 <- scale(train_data[, features1])
test_features1 <- scale(test_data[, features1])
# --- Model 1: Using a broad set of physical measurement features ---
features1 <- c("sex", "length", "diameter", "height", "whole_weight",
"shucked_wieght", "viscera_wieght", "shell_weight")
# Normalize the features for both training and testing sets.
# kNN is sensitive to the scale of data, so normalization is crucial.
train_features1 <- scale(train_data[, features1])
test_features1 <- scale(test_data[, features1])
# Train the kNN model with k=5
knn_pred1 <- knn(train = train_features1,
test = test_features1,
cl = train_labels,
k = 5)
# Create a contingency table (confusion matrix) to evaluate the model.
cat("--- Model 1: Broad Feature Set ---\n")
cont_table1 <- table(Predicted = knn_pred1, Actual = test_labels)
print("Contingency Table for Model 1:")
print(cont_table1)
# Calculate and print the accuracy of Model 1.
accuracy1 <- sum(diag(cont_table1)) / sum(cont_table1)
cat("Accuracy for Model 1:", round(accuracy1, 4), "\n\n")
# --- Model 2: Using a smaller, more focused subset of features ---
features2 <- c("length", "diameter", "height", "shell_weight")
# Normalize the features for the second model.
train_features2 <- scale(train_data[, features2])
test_features2 <- scale(test_data[, features2])
# Train the kNN model with k=5
knn_pred2 <- knn(train = train_features2,
test = test_features2,
cl = train_labels,
k = 5)
# Evaluate Model 2 using a contingency table.
cat("--- Model 2: Focused Feature Set ---\n")
cont_table2 <- table(Predicted = knn_pred2, Actual = test_labels)
print("Contingency Table for Model 2:")
print(cont_table2)
# Calculate and print the accuracy of Model 2.
accuracy2 <- sum(diag(cont_table2)) / sum(cont_table2)
cat("Accuracy for Model 2:", round(accuracy2, 4), "\n\n")
# Determine which model performed better based on accuracy.
if (accuracy1 > accuracy2) {
cat("Model 1 performed better. Finding optimal k for this model.\n")
better_train_features <- train_features1
better_test_features <- test_features1
} else {
cat("Model 2 performed better. Finding optimal k for this model.\n")
better_train_features <- train_features2
better_test_features <- test_features2
}
# --- Tune k for the better model (testing k from 1 to 30) ---
k_values <- 1:30
accuracies <- numeric(length(k_values)) # Vector to store accuracies
# Loop through each k value, train a model, and record its accuracy.
for (i in seq_along(k_values)) {
k <- k_values[i]
knn_pred_tune <- knn(train = better_train_features,
test = better_test_features,
cl = train_labels,
k = k)
cont_table_tune <- table(Predicted = knn_pred_tune, Actual = test_labels)
accuracies[i] <- sum(diag(cont_table_tune)) / sum(cont_table_tune)
}
# Find the optimal k that yields the highest accuracy.
optimal_k <- k_values[which.max(accuracies)]
max_accuracy <- max(accuracies)
cat("\n--- Optimal k Value ---\n")
cat("Optimal k:", optimal_k, "\n")
cat("Highest Accuracy Achieved:", round(max_accuracy, 4), "\n\n")
# Create a data frame for plotting the results.
accuracy_df <- data.frame(k = k_values, Accuracy = accuracies)
# Plot Accuracy vs. k-Value to visualize the optimal k.
ggplot(accuracy_df, aes(x = k, y = Accuracy)) +
geom_line(color = "dodgerblue", size = 1) +
geom_point(color = "dodgerblue") +
geom_vline(xintercept = optimal_k, linetype = "dashed", color = "red") +
labs(title = "k-NN Performance: Accuracy vs. Number of Neighbors (k)",
subtitle = paste("Optimal k =", optimal_k, "with Accuracy =", round(max_accuracy, 4)),
x = "k (Number of Neighbors)",
y = "Model Accuracy") +
theme_minimal()
help(cat)
# Create a contingency table (confusion matrix) to evaluate the model.
print("--- Model 1: Broad Feature Set ---\n")
cont_table1 <- table(Predicted = knn_pred1, Actual = test_labels)
print("Contingency Table for Model 1:")
print(cont_table1)
# Load libraries for clustering and visualization
library(cluster)
library(factoextra)
install.packages("factoextra")
# Load libraries for clustering and visualization
library(cluster)
library(factoextra)
# We will use the scaled feature set from the better performing kNN model
# The 'better_train_features' variable holds this data.
# For this exercise, we'll use the full dataset with the best features for clustering.
best_features_scaled <- scale(abalone_data[, head(features1, -1)]) # Using Model 1 features as it was better
# 1. Find the optimal number of clusters (K) for K-Means
# We use the silhouette method to find the optimal K.
cat("\n--- Finding Optimal K for K-Means ---\n")
kmeans_opt_k_plot <- fviz_nbclust(best_features_scaled, kmeans, method = "silhouette") +
labs(subtitle = "Optimal K for K-Means (Silhouette Method)")
print(kmeans_opt_k_plot)
# From the plot, we determine the optimal k (the one with the highest avg. silhouette width)
# Let's assume the plot suggests K=2 is optimal. We will proceed with that.
optimal_k_kmeans <- 2
cat("Optimal K for K-Means is:", optimal_k_kmeans, "\n\n")
kmeans_model <- kmeans(best_features_scaled, centers = optimal_k_kmeans, nstart = 25)
# 3. Create a silhouette plot for the K-Means model
cat("--- K-Means Silhouette Plot ---\n")
kmeans_silhouette <- silhouette(kmeans_model$cluster, dist(best_features_scaled))
kmeans_sil_plot <- fviz_silhouette(kmeans_silhouette) +
labs(title = "K-Means Silhouette Plot",
subtitle = paste("k =", optimal_k_kmeans))
print(kmeans_sil_plot)
# 1. Find the optimal number of clusters (K) for PAM
cat("\n--- Finding Optimal K for PAM ---\n")
pam_opt_k_plot <- fviz_nbclust(best_features_scaled, pam, method = "silhouette") +
labs(subtitle = "Optimal K for PAM (Silhouette Method)")
